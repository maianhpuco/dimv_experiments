---
title: "classification_experiement_v9 - implement DIMVf"
output:
  pdf_document: default
  html_document: default
date: "2022-09-30"
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE, echo=TRUE, eval = TRUE)
``` 


```{r}
require(knitr)
FILE_NAME = 'v12'
purl("imputation.Rmd", output = 'imputation.R')
```

```{r}
packages <- c(
  "missMDA", 
  "softImpute", 
  "caret", 
  "caTools", 
  "glue", 
  "jsonlite", 
  "future.apply",
  "dslabs", 
  "cowplot", 
  "magick", 
  "progress", 
  "datasets", 
  "stats", 
  "foreach",
  "fdm2id", 
  "datasetsICR", 
  "HDclassif", 
  "readxl", 
  "httr"
)
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE)) 

library(here) 
source(here('src/rscript/dimv.R'))  
source(here('src/rscript/dpers.R'))   
source(here('src/rscript/utils.R'))    
source(here('src/rscript/imputation_comparation.R'))     

plan(multisession, workers = 8)
```


<!-- ```{r} -->
<!-- library(readxl) -->
<!-- library(httr) -->
<!-- packageVersion("readxl") -->


<!-- url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00192/BreastTissue.xls' -->
<!-- GET(url, write_disk(new_tf <- tempfile(fileext = ".xls"))) -->
<!-- df <- read_excel(new_tf, sheet=2) -->
<!-- df -->
<!-- ``` -->

# READING DATASETS: 

```{r}
read_excel_url <- function(url, sheet_num){
  GET(url1, write_disk(tf <- tempfile(fileext = ".xls")))
  df <- read_excel(tf, sheet=2) 
  unlink(tf)
  return(df)
} 

parkinsons_path = 'http://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data' 

```


```{r}

parkinsons = read.csv()
parkinsons

```

```{r}
new_thyroid = read.csv('https://archive.ics.uci.edu/ml/machine-learning-databases/thyroid-disease/new-thyroid.data')
new_thyroid
```
```{r}
breast_cancer_wisconsin=read.csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data')
breast_cancer_wisconsin
```



```{r}
df
```

```{r}

```

```{r}
read_excel_url('https://archive.ics.uci.edu/ml/machine-learning-databases/00192/BreastTissue.xls', 2)
```


```{r}
df <- read_excel(tf, sheet=1)
df
```

```{r}
library(openxlsx)
df = read.xlsx(install.packages',sheet=2) 
```

```{r}
library(tidyverse)
library(rio)
install.packages(rio)
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/00192/BreastTissue.xls'
rio::import(file = url,which = 2) %>% 
  glimpse() 
```

 
```{r}
data(iris)
data(ionosphere)
data(seeds) 
data(wine)
```

```{r}

curr_dir = getwd()
path = '../../data/mnist/raw/'

mnist_path = file.path(curr_dir, path) 
print(mnist_path)

if (!file.exists(file.path(mnist_path, "train-images-idx3-ubyte")) |
  !file.exists(file.path(mnist_path, "t10k-images-idx3-ubyte")) |
  !file.exists(file.path(mnist_path, "train-labels-idx1-ubyte")) |
  !file.exists(file.path(mnist_path, "t10k-labels-idx1-ubyte")) 
  ){
  
  # getting the data 
  mnist <- read_mnist(
    path = NULL,
    destdir = mnist_path, 
    download = TRUE,
    url = "https://www2.harvardx.harvard.edu/courses/IDS_08_v2_03/",
    keep.files = TRUE
  )  
  
  # clear folder data (avoid wrong zipping)
  list_files = list.files(path=mnist_path) 
  for (x in 1:length(list_files)){
    file_path = file.path(mnist_path, list_files[x]) 
    if (substring(file_path, nchar(file_path)-2, nchar(file_path)) == '.gz'){
      R.utils::gunzip(file_path, overwrite=TRUE, remove=FALSE) 
    }
    }  
}  
```

```{r}

impDi <- function(S, Xtest, threshold, nlargest=2){
  print("start imputation")
  Xtest[is.na(Xtest)] <- NaN   
  Xpred_original = Xtest
  
  #not to apply the algorithm on the ZERO VARIANCE columns, just fill the with 0 / or mean value (which is also 0)
  non_zero_var = (which(diag(S)!=0)) 
  
  Xtest = Xpred_original[, non_zero_var, drop=F] 
  Xpred = Xpred_original[, non_zero_var, drop=F] 
  S = S[non_zero_var, non_zero_var, drop=F]
  

  missingCols =  which(colSums(is.na(Xtest)) > 0) 
  print(missingCols)
  if (length(missingCols)==0){
    print("There is no missing value feature")
    return(Xpred_original)
  }

  DIMV1feature <- function(f){
    print(f)
    
    setF = which(abs(S[,f]) >= threshold)  
    print(setF)
    #setF : Col with high corr with f
    #Fos need to be exist setF need to have at least one pair with different missing pattern f
    naRows = which(is.na(Xtest[,f]))
    #if there only 1 col have high correlation with f, and it has same missing pattern with f then find 1 other column have the highest correlation with f (and of course  corr lower than threshold)
    ColInSetFExistAtLeast1SameMissingValueAsf <- function(setF, naRow){ #list of True False = 
      return(
             sum(!is.na(Xtest[naRow, setF,drop=F]))#number of cell have missing value same as f  in setF
      )
    }  
    for (naRow in naRows){
      flag = (
              sum(ColInSetFExistAtLeast1SameMissingValueAsf(setF, naRow))==0
              )
      if (flag==T){
        tempS = S; diag(tempS) <- NA
        samePatternFeatures = which(
            colSums(is.na(Xtest[naRow,,drop=F])) == 1
        )
        tempS[samePatternFeatures, samePatternFeatures] <- NA;
        mostSimilarCols <- order(
                tempS[,f,drop=F],
                decreasing = TRUE)[seq_len(nlargest)];
        setF_added = arrayInd(
                mostSimilarCols,
                dim(tempS[,f,drop=F]),
                useNames = TRUE)[, 1]
        setF = c(setF, setF_added)
      }
    }

    i = which(missingCols==f)  
    setTxtProgressBar(pb, i)  
    
    Df_row_pool = which(is.na(Xtest[, f])) 
    
    # after having setF and f, we then find similar missing pattern in each row 
    while (length(Df_row_pool) > 0){
      s = Df_row_pool[1]
      Fos = intersect(which(!is.na(Xtest[s,,drop=F])), setF)
      Fms = intersect(which(is.na(Xtest[s,,drop=F])), setF) 
      
      #6 lines below is to calculate Z 
      maskOfXtestFilterFos = matrix(0, dim(Xtest)[1], dim(Xtest)[2]) 
      maskOfXtestFilterFos[Df_row_pool, Fos] = Xtest[Df_row_pool, Fos] 
      Z_row_ids_fiter_observed = intersect(which(rowSums(is.na(maskOfXtestFilterFos[, Fos,drop=F]))==0), Df_row_pool)
      maskOfXtestFilterFms = matrix(0, dim(Xtest)[1], dim(Xtest)[2])
      maskOfXtestFilterFms[Z_row_ids_fiter_observed, Fms] = Xtest[Z_row_ids_fiter_observed, Fms] 
      Z_row_ids_fiter_missing = which(rowSums(is.na(maskOfXtestFilterFms))==length(Fms))  
      
      Z_row_ids = Z_row_ids_fiter_missing
      
      So = S[Fos, Fos]
      Smo = S[Fos, f] 
      beta = solve(So) %*% Smo
      
      Xtest[Z_row_ids, f] = t(beta) %*% t(Xtest[Z_row_ids, Fos, drop=F])
      Df_row_pool <- setdiff(Df_row_pool, Z_row_ids)  
      
    }
    return(Xtest[, f])
  }
  
  total = length(missingCols)
  
  
  pb <- txtProgressBar(min = 0, max = total, style = 3)  
  # run the DIMV1feature parallely on every single features  
  Xpred_result= future_lapply(missingCols, DIMV1feature)
  Xpred[, missingCols] = t(do.call(rbind, Xpred_result)) 
  
  Xpred_original[, non_zero_var] = Xpred
  Xpred_original[is.nan(Xpred_original)]=0
  
  return(Xpred_original) 
}    
```


```{r}
load_image_file = function(filename) {
  ret = list()
  f = file(filename, 'rb')
  readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  n    = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  nrow = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  ncol = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  x = readBin(f, 'integer', n = n * nrow * ncol, size = 1, signed = FALSE)
  close(f)
  data.frame(matrix(x, ncol = nrow * ncol, byrow = TRUE))
}

# load label files
load_label_file = function(filename) {
  f = file(filename, 'rb')
  readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  n = readBin(f, 'integer', n = 1, size = 4, endian = 'big')
  y = readBin(f, 'integer', n = n, size = 1, signed = FALSE)
  close(f)
  y
}  


processing_mnist_data <- function (){
  train = load_image_file(file.path(mnist_path, "train-images-idx3-ubyte"))
  test  = load_image_file(file.path(mnist_path,"t10k-images-idx3-ubyte")) 

  train$label =  as.factor(load_label_file(file.path(mnist_path,"train-labels-idx1-ubyte")))

  test$label = as.factor(load_label_file(file.path(mnist_path,"t10k-labels-idx1-ubyte")))
  result = list('train'=train, 'test'=test)
  return(result)
} 
```

```{r}
processed_data = processing_mnist_data()
train = processed_data$train 
test = processed_data$test
shuffle = sample(1:nrow(train))

train = train[shuffle, ]
test = test[shuffle, ]

X.train = train[, -785][1:1000, ]
X.test = test[, -785][1:500, ]
y.train = train[, 785, drop=F]
y.test = test[, 785, drop=F]

data = train[shuffle, ][, -785][1:10000,]
labels = train[shuffle, ][,785,drop=F][1:10000,,drop=F]

labels=as.numeric(factor(labels$label))   
labels 
```




```{r}
visualize_digit <- function(missing_X, y, train_removed_rows, per_col, per_row){

  par(mfcol=c(per_col, per_row))
  par(mar=c(0, 0, 3, 0), xaxs='i', yaxs='i')  
 
  for (idx in 1:(per_col*per_row)) { 
      im <- matrix(unlist(missing_X[train_removed_rows, ][idx, ]),nrow = 28,byrow = T)
      im <- t(apply(im, 2, rev)) 
      image(1:28, 1:28, im,  xaxt='n', main=paste(y[train_removed_rows,,drop=F][idx, ])) 
  }

} 

```



READING DATA 

```{r}
createRandomlyMissingData = function(data, rate){
  data = as.matrix(data)
  col_num = dim(data)[2] 
  flatten = as.vector(data) 
  
    
  mask = runif(length(flatten), min = 0, max = 1) < rate
  flatten[mask]=NaN
  return(matrix(flatten, ncol = col_num))
}
```


```{r}
missing.mnist = createRandomlyMissingData(X.train, 0.5)
dim(y.train)

```



```{r}
  X_train[is.na(Xtrain)] <- NaN
  sigmaDper = dpers(X.train)
  
  X_imp.train = impDi(sigmaDper, X.train, threshold)[,, drop=F]
  #b) on testing set   
  X.test[is.na(X.test)] <- NaN
  X_imp.test = impDi(sigmaDper, X.test, threshold)[,, drop=F]
  
  result = list("train" = X_imp.train, "test" = X_imp.test)
  return(result) 
```



```{r}
  missing.Xtrain[is.na(missing.Xtrain)] <- NaN
  sigmaDper = dpers(missing.Xtrain) 
  sigmaDper
```


```{r}

impDi_run <- function(X.train, y.train, X.test, y.test, threshold=.3){ 
  #a) on training set 
  X.train[is.na(X.train)] <- NaN
  sigmaDper = dpers(X.train)
  
  X_imp.train = impDi(sigmaDper, X.train, threshold)[,, drop=F]
  #b) on testing set   
  X.test[is.na(X.test)] <- NaN
  X_imp.test = impDi(sigmaDper, X.test, threshold)[,, drop=F]
  
  result = list("train" = X_imp.train, "test" = X_imp.test)
  return(result)
} 
 
```

```{r}
dim(as.matrix(labels))
```


```{r}
dim(data)
missing_data =  createRandomlyMissingData(data, 0.2) 
folds = createFolds(labels, k=5)  
folds
test_filter = unlist(unname(folds[1]))   
test_filter
missing.X_train = missing_data[-test_filter, ] 
missing.X_test = missing_data[test_filter, ]
y.train = as.matrix(labels)[-test_filter,,drop=F]
y.test = as.matrix(labels)[test_filter,,drop=F]  

train_normed = normalizing(x=missing.X_train, Xtrain=missing.X_train)
missing.X_train_normed = train_normed$X_normed  
test_normed = normalizing(x=missing.X_test, Xtrain=missing.X_train)
missing.X_test_normed = test_normed$X_normed  

missing.X_train_normed[is.na(missing.X_train_normed)] <- NaN 
  
sigmaDpers = dpers(missing.X_train_normed)
```




```{r}
dim(missing.X_train_normed)
dim(X_imp.train)
filter_nan = is.na(missing.X_train_normed)
filter_nan
copy = X_imp.train 


reconstructingNormedMatrix()

X_rescaled = 
copy[filter_nan] = NaN
copy
visualize_digit(copy, y.train, 1:20, 2,6)
```
```{r}
reconstructingNormedMatrix <- function(X_norm, mean, std){
  mult = sweep(X_norm, 2, std, '*')
  reconstrc = sweep(mult, 2, mean, '+')
  return (reconstrc)
} 

Xtrain_rescaled = reconstructingNormedMatrix(X_imp.train, train_normed$mean, train_normed$sd)


```

```{r}

copy_rescaled = Xtrain_rescaled
copy_rescaled[filter_nan==F] = NaN 


visualize_digit(copy_rescaled, y.train, 1:100, 2,6)




``` 

```{r}
data
```

```{r}
folds = createFolds(labels, k=5)  
```


```{r}

dim(data)
random_data = data[1:5000,]
random_labels = labels[1:5000, ]
length(random_labels)
missing_data =  createRandomlyMissingData(random_data, 0.1) 

test_filter = unlist(unname(folds[1]))   

length(test_filter)

random.missing.X_train = missing_data[-test_filter, ] 
random.missing.X_test = missing_data[test_filter, ]
random.y.train = as.matrix(random_labels)[-test_filter,,drop=F]
random.y.test = as.matrix(random_labels)[test_filter,,drop=F]  
dim(random.missing.X_train)
dim(random.y.train)
dim(random.missing.X_test)
dim(random.y.test)


random.train_normed = normalizing(x=random.missing.X_train, Xtrain=random.missing.X_train)
random.missing.X_train_normed = random.train_normed$X_normed  

random.test_normed = normalizing(x=random.missing.X_test, Xtrain=random.missing.X_train)
random.missing.X_test_normed = test_normed$X_normed  

random.missing.X_train_normed[is.na(random.missing.X_train_normed)] <- NaN 
  
random.sigmaDpers = dpers(random.missing.X_train_normed) 



random_imp_1000 = impDi_run(
  random.missing.X_train_normed, 
  random.y.train, 
  random.missing.X_test_normed,
  randim.y.test, 
  threshold = 0.1)
 

train_rm_1000 = 
  which(rowSums(is.na(missing.Xtrain_normed[new_idx_train,,drop=F][1:5000, ]))>0)


old_imp_1000_reconstruct = reconstructingNormedMatrix(
  old_imp_1000$train, train_normed$mean, train_normed$sd)

length(new_idx_train)
dim(y_train[new_idx_train,,drop=F][1:5000,,drop=F])
length(train_removed_rows_1000)
dim(old_imp_1000_reconstruct)

visualize_digit(old_imp_1000_reconstruct, y_train[new_idx_train,,drop=F][1:5000,,drop=F], train_rm_1000, 2,6)   
```
```{r}
image_edge_deleting <- function(
    data, 
    delete_type, #by_percent, by_pixel_number 
    percents_of_data,
    image_width,
    image_height,
    width_del_percent=0, 
    height_del_percent=0,
    from_pixel_width=None, 
    from_pixel_height=None
    ){
  if (delete_type =='by_percent'){
    n = dim(data)[2]
    from_pixel_width = ceiling((1-width_del_percent)*image_width)   
    from_pixel_height = ceiling((1-height_del_percent)*image_height)
  }
  if (delete_type=='by_pixel_number'){
    from_pixel_width = from_pixel_width
    from_pixel_height = from_pixel_height
  }
  get_image_position_spatial_to_flatten<- function(delImgPosWidth, delImgPosHeight){ 
    # delImgPosHeight: row 
    # delImgPosWeight : col 
    tmp = c(1:784)
    im <- matrix(unlist(tmp),nrow = 28,byrow = T)
    idxs = im[delImgPosHeight, delImgPosWidth]  
    return(matrix(idxs,nrow = 1,byrow = T)[, ])
  } 
  
flatten_columns_removed = get_image_position_spatial_to_flatten(
  from_pixel_width:image_width,
  from_pixel_height: image_height
)

  flatten_rows_removed = sample.int(nrow(data), as.integer(nrow(data)*percents_of_data))
  missing_data = data
  missing_data[flatten_rows_removed, flatten_columns_removed] <- NA
  result = list(
    'missing_data'=missing_data, 
    'flatten_columns_removed'=flatten_columns_removed,  
    'flatten_rows_removed'=flatten_rows_removed
  ) 
  return(result)
}
 
```


```{r}
  
  
  length(labels)
  dim(data)
  labels = as.matrix(labels)
  
  X_train = as.matrix(data[-test_filter,])
  X_test = as.matrix(data[test_filter,])
  
  y_train = as.matrix(labels[-test_filter])[,,drop=F]
  y_test = as.matrix(labels[test_filter])[,,drop=F]
  dim(y_train)
  
  width_del_percent = 0.5 
  height_del_percent = 0.5 
  sample_deleted_percent = 0.5 
  #cut a piece of image 
  removed_train = image_edge_deleting(
    X_train,
    'by_percent', 
    sample_deleted_percent, 28, 28, 
    width_del_percent=width_del_percent,
    height_del_percent=height_del_percent)
  
  removed_test= image_edge_deleting(
    X_test,
    'by_percent', 
    sample_deleted_percent, 28,28,
    width_del_percent=width_del_percent,
    height_del_percent=height_del_percent)  
  
  train_removed_rows = removed_train$flatten_rows_removed
  test_removed_rows = removed_test$flatten_rows_removed
  train_removed_columns = removed_train$flatten_columns_removed 
  test_removed_columns = removed_test$flatten_columns_removed 
  
  
  
  missing.Xtrain = removed_train$missing_data
  missing.Xtest =  removed_test$missing_data  
  # normalization 
  
  
  train_normed = normalizing(x=missing.Xtrain, Xtrain=missing.Xtrain)
  
  missing.Xtrain_normed = train_normed$X_normed
  missing.Xtrain_mean = train_normed$mean
  missing.Xtrain_sd = train_normed$sd 
  
  test_normed = normalizing(x=missing.Xtest, Xtrain=missing.X_train)
  missing.Xtest_normed = test_normed$X_normed 
```






```{r}
old_imp = impDi_run(missing.Xtrain_normed, y.train, missing.Xtest_normed, y.test, threshold = 0.1)
```

```{r}
visualize_digit(removed_train$missing_data,  y_train, train_removed_rows, 2, 6) 
```


removed_train$missing_data 
```{r}
visualize_digit(missing.Xtrain_normed, y_train, train_removed_rows, 2, 6)
``` 

```{r}
#10000 dataset 
train_normed$sd
old_imp_rescaled  = reconstructingNormedMatrix(old_imp$train, train_normed$mean, train_normed$sd)
visualize_digit(old_imp_rescaled, y_train, train_removed_rows, 2,6)

``` 

```{r}
new_idx_train = sample(1: nrow(missing.Xtrain_normed))
new_idx_test = sample(1: nrow(missing.Xtest_normed))


old_imp_1000 = impDi_run(
  missing.Xtrain_normed[new_idx_train,,drop=F][1:2000, ], 
  y.train[new_idx_train, ][1:2000,,drop=F], 
  missing.Xtest_normed[new_idx_test, ][1:100, ],
  y.test[new_idx_test, ][1:100, drop=F], 
  threshold = 0.1)
 

train_rm_1000 = 
  which(rowSums(is.na(missing.Xtrain_normed[new_idx_train,,drop=F][1:2000, ]))>0)


old_imp_1000_reconstruct = reconstructingNormedMatrix(
  old_imp_1000$train, train_normed$mean, train_normed$sd)

length(new_idx_train)
dim(y_train[new_idx_train,,drop=F][1:2000,,drop=F])
length(train_removed_rows_1000)
dim(old_imp_1000_reconstruct)

visualize_digit(old_imp_1000_reconstruct, y_train[new_idx_train,,drop=F][1:2000,,drop=F], train_rm_1000, 2,6) 

```
```{r}
new_idx_train = sample(1: nrow(missing.Xtrain_normed))
new_idx_test = sample(1: nrow(missing.Xtest_normed))


old_imp_1000 = impDi_run(
  missing.Xtrain_normed[new_idx_train,,drop=F][1:5000, ], 
  y.train[new_idx_train, ][1:5000,,drop=F], 
  missing.Xtest_normed[new_idx_test, ][1:100, ],
  y.test[new_idx_test, ][1:100, drop=F], 
  threshold = 0.1)
 

train_rm_1000 = 
  which(rowSums(is.na(missing.Xtrain_normed[new_idx_train,,drop=F][1:5000, ]))>0)


old_imp_1000_reconstruct = reconstructingNormedMatrix(
  old_imp_1000$train, train_normed$mean, train_normed$sd)

length(new_idx_train)
dim(y_train[new_idx_train,,drop=F][1:5000,,drop=F])
length(train_removed_rows_1000)
dim(old_imp_1000_reconstruct)

visualize_digit(old_imp_1000_reconstruct, y_train[new_idx_train,,drop=F][1:5000,,drop=F], train_rm_1000, 2,6)  
```



```{r}
idx=1
im <- matrix(unlist(copy[idx, ]),nrow = 28,byrow = T)
im <- t(apply(im, 2, rev)) 
image(1:28, 1:28, im,  xaxt='n', main=paste(y[train_removed_rows,,drop=F][idx, ])) 
```

```{r}
copy[1, ]


```

```{r}
copy = X_imp.train 

copy[filter_nan==F] = NaN
copy 
visualize_digit(copy, y.train, 1:20, 2,6)

```

```{r}
copy[1, ]
```


```{r}
X_imp.train = impDi(sigmaDpers, missing.X_train_normed, 0.1)[,, drop=F]
  
```




```{r}

reconstructingNormedMatrix <- function(X_norm, mean, std){
  mult = sweep(X_norm, 2, std, '*')
  reconstrc = sweep(mult, 2, mean, '+')
  return (reconstrc)
} 

Xtrain_rescaled = reconstructingNormedMatrix(X_imp.train, train_normed$mean, train_normed$sd)


```



```{r}
visualize_digit(missing.X_train, y.train, 1:100, 2,6)
```


```{r}
visualize_digit(missing.X_train_normed, y.train, 1:100, 2,6)
```


```{r}
visualize_digit(Xtrain_rescaled, y,train, 1:50, 2,6)
```




```{r}
dim(sigmaDpers)
sum(which(is.na(sigmaDpers)==F))
sum(which(is.na(sigmaDpers)==T))
```



```{r}
test_filter
labels = as.numeric(factor(labels_origin[shuffled_idx, ]))    
```


```{r}
visualize_digit(missing.X_test, y.test, 1:100, 2, 6) 
```


```{r, message = FALSE, warning = FALSE}
summary_result <- function(result, caclCol, groupByCol, fold_number, dataset_name, missing_rate, order_decreasing=TRUE){
  result$col = as.numeric(result[, caclCol]) 
  result$imputation  = result[, groupByCol]
  summary = data.frame(
                  group=levels(factor(result$imputation)), 
                  mean=(aggregate(result$col, by=list(result$imputation), FUN=mean)$x),
                  sd=(aggregate(result$col, by=list(result$imputation), FUN=sd)$x), 
                  iteration_times = max(result$fold_number)
             )
  summary = summary[order(summary$mean, decreasing=order_decreasing), ]   
  summary$dataset_name = dataset_name
  summary$missing_rate = missing_rate
  return(summary)
} 
``` 


```{r}
summary_all_result <- function(result, acc_col="accuracy", mse_train_col="rmse_train", mse_test_col="rmse_test", groupByCol="imputation_method", iteration="fold_number"){
  result$accuracy = as.numeric(result[, acc_col]) 
  result$mse_train = as.numeric(result[, mse_train_col])
  result$mse_test = as.numeric(result[, mse_test_col])
  
  result$imputation  = result[, groupByCol]
  
  summary = data.frame(
        group=levels(factor(result$imputation)), 
        
        accuracy_mean=(aggregate(result$accuracy, by=list(result$imputation), FUN=mean)$x),
        accuracy_sd=(aggregate(result$accuracy, by=list(result$imputation), FUN=sd)$x),  
        
        mse_train_mean=(aggregate(result$mse_train, by=list(result$imputation), FUN=mean)$x),
        mse_train_sd=(aggregate(result$mse_train, by=list(result$imputation), FUN=sd)$x), 
        
        mse_test_mean=(aggregate(result$mse_test, by=list(result$imputation), FUN=mean)$x),
        mse_test_sd=(aggregate(result$mse_test, by=list(result$imputation), FUN=sd)$x),  
        
        folds = max(result$fold_number)
         )
  
  summary = summary[order(summary$accuracy_mean, decreasing=T),]   
  summary$accuracy_ranking = rank(-summary$accuracy_mean)
  summary$mse_ranking = rank(summary$mse_test_mean)
  return(summary)
}  

```


```{r}
imputeAndPredictionOnEachFold <- function(fold, missing_data, data, labels, folds, dataset_name, DIMVthreshold){ 
  test_filter = unlist(unname(folds[fold])) 
  
  #filter fold's data 
  rmse_calc <- function(ori_data, imputed_rescaled_data,missing_pos_filter){
    nominator = sum((missing_pos_filter * ori_data - missing_pos_filter * imputed_rescaled_data)**2)
    denominator = sum(missing_pos_filter) 
    return(sqrt(nominator/denominator))
  }
  reconstructingNormedMatrix <- function(X_norm, mean, std){
    mult = sweep(X_norm, 2, std, '*')
    reconstrc = sweep(mult, 2, mean, '+')
    return (reconstrc)
  }
  labels = as.factor(labels)
  
  missing.X_train = missing_data[-test_filter, ] 
  missing.X_test = missing_data[test_filter, ]
  y.train = labels[-test_filter]
  y.test = labels[test_filter]  
  
  train_normed = normalizing(x=missing.X_train, Xtrain=missing.X_train)
  missing.X_train_normed = train_normed$X_normed
  missing.X_train_mean = train_normed$mean
  missing.X_train_sd = train_normed$sd 
  
  test_normed = normalizing(x=missing.X_test, Xtrain=missing.X_train)
  missing.X_test_normed = test_normed$X_normed 
  
  
  func_list = list( 
    'impDi_run', 
    'softImpute_run', 
    'mice_run', 
    'imputePCA_run',  
    'kNNimpute_run', 
    'missForest_run'
    )   
    
  for(j in 1:length(func_list)){
    func_name = unlist(strsplit(func_list[[j]], "_run"))[1] 

    tstart = Sys.time() 
    func <- get(func_list[[j]])  
    if (func_name == "impDi"){
      impted = func(missing.X_train_normed , y.train, missing.X_test_normed, y.test, threshold=0.3)
    }else{
      impted = func(missing.X_train_normed , y.train, missing.X_test_normed, y.test)   
    }
    
    set.seed(1)

    fit.svm = train(as.data.frame(impted$train), y.train, method="svmRadial") 
    
  
    pred <- predict(fit.svm, as.data.frame(impted$test))

    pred <- as.factor(pred)
    acc = mean(pred == y.test)
    
    rmse_train = rmse_calc(
      as.matrix(data[-test_filter,]), 
      reconstructingNormedMatrix(impted$train, missing.X_train_mean, missing.X_train_sd), 
      is.na(missing.X_train)*1 
      )
    
    rmse_test = rmse_calc(
      as.matrix(data[test_filter,]), 
      reconstructingNormedMatrix(impted$test, missing.X_train_mean, missing.X_train_sd),
      is.na(missing.X_test)*1 
      )
     
    
    result = data.frame( 
              list("dataset" = dataset_name, 
                    "fold_number" = fold, 
                    "imputation_method" =  func_name,
                    "accuracy" = acc,
                    "rmse_train" = rmse_train, 
                    "rmse_test" = rmse_test
              ) ) 
    
    if (j > 1){
        results = rbind(results, result)
    }else{
        results = result 
    }
  }
  return(results)
}
```


```{r}
imputeAndClassificationPipeline <- function(
    dataset, 
    dataset_name, 
    label_col, 
    DIMVthreshold, 
    root, 
    folder_name, 
    missing_rate=0.3, 
    number_of_folds=10){  
 
  print(dataset_name)
  data = dataset[, !names(dataset) %in% c(label_col)]  
  labels_origin = dataset[, label_col,drop=F ]
  
   #shuffle  
  shuffled_idx = sample(1:nrow(data))  
  data = data[shuffled_idx, ] 
  labels = as.numeric(factor(labels_origin[shuffled_idx, ]))   
  

  
  missing_data = createRandomlyMissingData(data, missing_rate)  
  pb <- txtProgressBar(min = 0, max = number_of_folds, style = 3) 
  
  # results <- foreach::foreach(i = 1:number_of_folds, .combine='rbind') %dopar% {
  #   
  #   setTxtProgressBar(pb, i)  
  #   imputeAndPredictionOnEachFold(i, missing_data, data, labels, folds, dataset_name, DIMVthreshold)
  # }
  for (i in 1:number_of_folds){
    result = imputeAndPredictionOnEachFold(i, missing_data, data, labels, folds, dataset_name, DIMVthreshold) 
    print("iteration number")
    print(i)
    print(result)
    if (i == 1){
      results  = result
    }else{
      results = rbind(results, result)
    }
  }
  
  results = data.frame(results)
  acc_summary = summary_result(results, 'accuracy', 'imputation_method', "fold_number", dataset_name, missing_rate, order_decreasing=T)  
  rmse_test_summary = summary_result(results, 'rmse_test', 'imputation_method', "fold_number", dataset_name, missing_rate, order_decreasing=F)  
  rmse_train_summary = summary_result(results, 'rmse_train', 'imputation_method', "fold_number", dataset_name,missing_rate,  order_decreasing=F)  
  
  prediction_results = list("acc_summary" = acc_summary, "rmse_summary" = rmse_test_summary)
  
  
  curr_dir = getwd()
  if (dir.exists(file.path(root, dataset_name)) == F){
    dir.create(file.path(root, dataset_name))
  }
  
  if (dir.exists(file.path(root, dataset_name, folder_name))==F){
      dir.create(file.path(root, dataset_name, folder_name))
  }
   
  #path to save result 

  fold_results_dir = file.path(root, dataset_name, folder_name, "fold_results.csv") 
  summary_acc_dir = file.path(root, dataset_name, folder_name, 'acc_summary.csv')
  summary_mse_test_dir = file.path(root, dataset_name, folder_name, 'rmse_test_summary.csv')
  summary_mse_train_dir = file.path(root, dataset_name, folder_name, 'rmse_train_summary.csv') 

  write.csv(results, fold_results_dir)
  write.csv(acc_summary, summary_acc_dir) 
  write.csv(rmse_test_summary, summary_mse_test_dir)
  write.csv(rmse_train_summary, summary_mse_train_dir)
  print("done saving result")
  return(prediction_results)
} 
```


```{r}
# 
# DIMV_THRESHOLD = 0.1
# MISSING_RATE = 0.1# the best 
# NUM_FOLDS = 2

executeImputeAndClassification <- function(DIMV_THRESHOLD, MISSING_RATE, NUM_FOLDS, SAVED_RESULT_PATH){
  root = SAVED_RESULT_PATH 
  print("-----Start")
  
  formatFloat2String <- function(float_value){
    i = as.integer(float_value*100) 
    s = if (as.integer(i/10) < 1){paste0("0", toString(i))}else{toString(i)} 
    return(s)
  } 
  
  folder_name = paste0(
    "missing_rate_",
    formatFloat2String(MISSING_RATE), 
    "_threshold_", 
    formatFloat2String(DIMV_THRESHOLD)
    )   
  print(folder_name)
  
  iris_result = imputeAndClassificationPipeline(
    iris, 
   	"iris", 
   	"Species", 
   	DIMV_THRESHOLD, 
   	root, 
   	folder_name, 
   	missing_rate=MISSING_RATE, 
   	number_of_folds=NUM_FOLDS)
  
  ionosphere_result = imputeAndClassificationPipeline(
    ionosphere,
   	"ionosphere",
   	"V35",
   	DIMV_THRESHOLD,
   	root,
   	folder_name,
   	missing_rate=MISSING_RATE,
   	number_of_folds=NUM_FOLDS)

  seeds_result = imputeAndClassificationPipeline(
    seeds,
   	"seeds",
   	"variety",
   	DIMV_THRESHOLD,
   	root,
   	folder_name,
   	missing_rate=MISSING_RATE,
   	number_of_folds=NUM_FOLDS)

  wine_result = imputeAndClassificationPipeline(
    wine,
   	"wine",
   	"class",
   	DIMV_THRESHOLD,
   	root,
   	folder_name,
   	missing_rate=MISSING_RATE,
   	number_of_folds=NUM_FOLDS)



  all_dataset_acc_summary = rbind(
    iris_result$acc_summary,
    ionosphere_result$acc_summary,
    seeds_result$acc_summary,
    wine_result$acc_summary
    )

  all_dataset_mse_summary = rbind(
    iris_result$mse_summary,
    ionosphere_result$mse_summary,
    seeds_result$mse_summary,
    wine_result$mse_summary
    )

  curr_dir = getwd()
  if (dir.exists(file.path(root, folder_name)) == F){
    dir.create(file.path(root, folder_name))
  }
   
  
  acc_dir = file.path(root, folder_name, "accuracy.csv") 
  mse_dir = file.path(root, folder_name, "rmse.csv")
  
  print(acc_dir)
  print(mse_dir)
  
  write.csv(all_dataset_acc_summary, acc_dir)
  write.csv(all_dataset_mse_summary, mse_dir)
} 

```





```{r}
# 
# root = "../../data/randomly_missing_dataset/svmRadial_20230112"   
# 
# NUM_FOLDS = 10
# 
# 
# DIMV_THRESHOLD_LIST = c(.3)
# MISSING_RATE_LIST = c(.1, .2, .3, .4)
# 
# total = length(DIMV_THRESHOLD_LIST) * length(MISSING_RATE_LIST)
# 
# print(total)
# count = 0 
# for (DIMV_THRESHOLD in DIMV_THRESHOLD_LIST){
#   for (MISSING_RATE in MISSING_RATE_LIST){
#     
#     repeat {
#     tmp<-try(
#       executeImputeAndClassification(DIMV_THRESHOLD, MISSING_RATE, NUM_FOLDS)
#     )
#     if (!(inherits(tmp,"try-error"))) 
#       break
#       } 
#      
#     
#     count = count+1 
#     print(paste(count, "/", total, " done"))
#   }
# }


```


```{r}
root = "../../data/randomly_missing_dataset/svmRadial_20230112"   
DIMV_THRESHOLD = 0.3 
MISSING_RATE=0.2
NUM_FOLDS = 5
  
formatFloat2String <- function(float_value){
    i = as.integer(float_value*100) 
    s = if (as.integer(i/10) < 1){paste0("0", toString(i))}else{toString(i)} 
    return(s)
} 
   
folder_name = paste0(
    "missing_rate_",
    formatFloat2String(MISSING_RATE), 
    "_threshold_", 
    formatFloat2String(DIMV_THRESHOLD)
    ) 

print(folder_name) 

iris_result = imputeAndClassificationPipeline(
    iris, 
   	"iris", 
   	"Species", 
   	DIMV_THRESHOLD, 
   	root, 
   	folder_name, 
   	missing_rate=MISSING_RATE, 
   	number_of_folds=NUM_FOLDS
    ) 

iris_result
```
```{r}

root = "../../data/randomly_missing_dataset/svmRadial_20230112"   
DIMV_THRESHOLD = 0.3 
MISSING_RATE=0.4
NUM_FOLDS = 5
  
formatFloat2String <- function(float_value){
    i = as.integer(float_value*100) 
    s = if (as.integer(i/10) < 1){paste0("0", toString(i))}else{toString(i)} 
    return(s)
} 
   
folder_name = paste0(
    "missing_rate_",
    formatFloat2String(MISSING_RATE), 
    "_threshold_", 
    formatFloat2String(DIMV_THRESHOLD)
    ) 
 

ionosphere_result = imputeAndClassificationPipeline(
    ionosphere, 
   	"ionosphere", 
   	"V35", 
   	DIMV_THRESHOLD, 
   	root, 
   	folder_name, 
   	missing_rate=MISSING_RATE, 
   	number_of_folds=NUM_FOLDS)  
```

```{r}
root = "../../data/randomly_missing_dataset/svmRadial_20230112"   
DIMV_THRESHOLD = 0.3 
MISSING_RATE=0.5
NUM_FOLDS = 5
  
formatFloat2String <- function(float_value){
    i = as.integer(float_value*100) 
    s = if (as.integer(i/10) < 1){paste0("0", toString(i))}else{toString(i)} 
    return(s)
} 
   
folder_name = paste0(
    "missing_rate_",
    formatFloat2String(MISSING_RATE), 
    "_threshold_", 
    formatFloat2String(DIMV_THRESHOLD)
    ) 
 

ionosphere_result = imputeAndClassificationPipeline(
    ionosphere, 
   	"ionosphere", 
   	"V35", 
   	DIMV_THRESHOLD, 
   	root, 
   	folder_name, 
   	missing_rate=MISSING_RATE, 
   	number_of_folds=NUM_FOLDS)  
```
```{r}
ionosphere_result
```

```{r}

```


```{r}
  ionosphere
  dataset = ionosphere
  dataset_name = "ionosphere"
  label_col = "V35"
  DIMVthreshold = 0.3 
  missing_rate=0.3 
  number_of_folds=5  
  
  
  
  print(dataset_name)
  dim(data)
  data = dataset[, !names(dataset) %in% c(label_col)]  
  labels_origin = dataset[, label_col,drop=F ]
  labels_origin
  
  
   #shuffle  
  shuffled_idx = sample(1:nrow(data)) 
  length(shuffled_idx)
  data = data[shuffled_idx, ] 
  labels = as.numeric(factor(labels_origin[shuffled_idx, ]))   
  labels

  folds = createFolds(labels, k=number_of_folds)
  folds
  missing_data = createRandomlyMissingData(data, missing_rate)
  dim(missing_data)
  pb <- txtProgressBar(min = 0, max = number_of_folds, style = 3) 
  
  # results <- foreach::foreach(i = 1:number_of_folds, .combine='rbind') %dopar% {
  #   setTxtProgressBar(pb, i)  
  #   imputeAndPredictionOnEachFold(i, missing_data, data, labels, folds, dataset_name, DIMVthreshold)
  # }
```



```{r}

# summary_all_result(results, acc_col="accuracy", mse_train_col="rmse_train", mse_test_col="rmse_test", groupByCol="imputation_method", iteration="fold_number") 
```

result, acc_col="accuracy", mse_train_col="mse_train", mse_test_col="mse_test", groupByCol="imputation_method", iteration="fold_number"

```{r}
  ionosphere
  dataset = ionosphere
  dataset_name = "ionosphere"
  label_col = "V35"
  DIMVthreshold = 0.3 
  missing_rate=0.3
  number_of_folds=5  
  
  
  
  
  print(dataset_name)
  dim(data)
  data = dataset[, !names(dataset) %in% c(label_col)]  
  labels_origin = dataset[, label_col,drop=F ]
  labels_origin
  
  
   #shuffle  
  shuffled_idx = sample(1:nrow(data)) 
  length(shuffled_idx)
  data = data[shuffled_idx, ] 
  labels = as.numeric(factor(labels_origin[shuffled_idx, ]))   
  labels

  folds = createFolds(labels, k=number_of_folds)
  folds
  missing_data = createRandomlyMissingData(data, missing_rate)
  dim(missing_data) 
  
  for (i in 1:5){
    print(i)
    result = imputeAndPredictionOnEachFold(i, missing_data, data, labels, folds, dataset_name, 0.3) 
    print(result)
    if (i==1){
      results = result
    }else{
      results = rbind(results, result)
    }
      
  }
  results
```


```{r}
#ionosphere_missing_30_threshold_30_5_folds = results 
summary_all_result(ionosphere_missing_30_threshold_30_5_folds) 
```

```{r}

  ionosphere
  dataset = ionosphere
  dataset_name = "ionosphere"
  label_col = "V35"
  DIMVthreshold = 0.3 
  missing_rate=0.5
  number_of_folds=5  
  
  
  data = dataset[, !names(dataset) %in% c(label_col)]  
  labels_origin = dataset[, label_col,drop=F ]
  labels_origin
  
  
   #shuffle  
  shuffled_idx = sample(1:nrow(data)) 
  length(shuffled_idx)
  data = data[shuffled_idx, ] 
  labels = as.numeric(factor(labels_origin[shuffled_idx, ]))   
  labels

  folds = createFolds(labels, k=number_of_folds)
  folds
  missing_data = createRandomlyMissingData(data, missing_rate)
  dim(missing_data) 
  
  for (i in 1:5){
    print(i)
    result = imputeAndPredictionOnEachFold(i, missing_data, data, labels, folds, dataset_name, 0.3) 
    print(result)
    if (i==1){
      ionosphere_missing_50_threshold_30_5_folds = result
    }else{
      ionosphere_missing_50_threshold_30_5_folds = rbind(results, result)
    }
      
  }
  summary_all_result(ionosphere_missing_50_threshold_30_5_folds)
```


```{r}
ionosphere_missing_30_threshold_30_5_folds = results 
summary_all_result(ionosphere_missing_30_threshold_30_5_folds)
```





```{r}



for (i in 1:5){
  print(i)
  result = imputeAndPredictionOnEachFold(i, missing_data, data, labels, folds, dataset_name, 0.1) 
  print(result)
  if (i==1){
    results = result
  }else{
    results = rbind(results, result)
  }
    
}
results 
```



```{r}
# -----------------------------------------------------------
  fold = 2
  test_filter = unlist(unname(folds[fold])) 
  test_filter
  #filter fold's data 
  rmse_calc <- function(ori_data, imputed_rescaled_data,missing_pos_filter){
    nominator = sum((missing_pos_filter * ori_data - missing_pos_filter * imputed_rescaled_data)**2)
    denominator = sum(missing_pos_filter) 
    return(sqrt(nominator/denominator))
  }
  reconstructingNormedMatrix <- function(X_norm, mean, std){
    mult = sweep(X_norm, 2, std, '*')
    reconstrc = sweep(mult, 2, mean, '+')
    return (reconstrc)
  }
  labels = as.factor(labels)
  labels
  missing.X_train = missing_data[-test_filter, ] 
  missing.X_test = missing_data[test_filter, ]
  y.train = labels[-test_filter]
  y.test = labels[test_filter]  
  
  train_normed = normalizing(x=missing.X_train, Xtrain=missing.X_train)
  missing.X_train_normed = train_normed$X_normed
  missing.X_train_mean = train_normed$mean
  missing.X_train_sd = train_normed$sd 
  
  missing.X_train_mean
  missing.X_train_sd
  data[1, ]
  test_normed = normalizing(x=missing.X_test, Xtrain=missing.X_train)
  missing.X_test_normed = test_normed$X_normed 
  missing_data[1, ]
  
  func_list = list( 
    'impDi_run', 
    'softImpute_run', 
    'mice_run', 
    'imputePCA_run',  
    'kNNimpute_run', 
    'missForest_run'
    )   
  
  imputed = impDi_run(missing.X_train_normed , y.train, missing.X_test_normed, y.test, threshold=0.3) 
  imputed$train[1, ]
  missing.X_train_normed[1, ]
  ori_norm = normalizing(x=as.matrix(data[-test_filter, ]), Xtrain=missing.X_train)$X_normed
  ori_norm[1, ]
  ori = as.matrix(data[-test_filter, ])
  recon = reconstructingNormedMatrix(imputed$train, missing.X_train_mean, missing.X_train_sd)
  mean(unname(as.matrix(data[-test_filter, ])[1, ]) - recon)**2
  
  r = rmse_calc(
      recon, 
      ori, 
      is.na(missing.X_train)*1 )
  r
  
  fit.svm = train(as.data.frame(impted$train), y.train, method="svmRadial") 
  
  for(j in 1:length(func_list)){
    func_name = unlist(strsplit(func_list[[j]], "_run"))[1] 

    tstart = Sys.time() 
    func <- get(func_list[[j]])  
    
    if (func_name == "impDi"){
      impted = func(missing.X_train_normed , y.train, missing.X_test_normed, y.test, threshold=DIMVthreshold)
    }else{
      impted = func(missing.X_train_normed , y.train, missing.X_test_normed, y.test)   
    }
    
    set.seed(1)

    fit.svm = train(as.data.frame(impted$train), y.train, method="svmRadial") 
    
  
    pred <- predict(fit.svm, as.data.frame(impted$test))

    pred <- as.factor(pred)
    acc = mean(pred == y.test)
    
    rmse_train = rmse_calc(
      as.matrix(data[-test_filter,]), 
      reconstructingNormedMatrix(impted$train, missing.X_train_mean, missing.X_train_sd), 
      is.na(missing.X_train)*1 
      )
    
    rmse_test = rmse_calc(
      as.matrix(data[test_filter,]), 
      reconstructingNormedMatrix(impted$test, missing.X_train_mean, missing.X_train_sd),
      is.na(missing.X_test)*1 
      )
     
    
    result = data.frame( 
              list("dataset" = dataset_name, 
                    "fold_number" = fold, 
                    "imputation_method" =  func_name,
                    "accuracy" = acc,
                    "rmse_train" = rmse_train, 
                    "rmse_test" = rmse_test
              ) ) 
    
    if (j > 1){
        results = rbind(results, result)
    }else{
        results = result 
    }
  }
  return(results) 
  
  
  
```




